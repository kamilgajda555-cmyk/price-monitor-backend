# üöÄ Szybki Start - Price Monitor

Ten przewodnik pomo≈ºe Ci uruchomiƒá aplikacjƒô w 10 minut.

## Krok 1: Wymagania

Upewnij siƒô, ≈ºe masz zainstalowane:
- **Docker** (wersja 20.10+)
- **Docker Compose** (wersja 2.0+)

Sprawd≈∫ wersje:
```bash
docker --version
docker-compose --version
```

## Krok 2: Rozpakowanie

```bash
tar -xzf price-monitor-app.tar.gz
cd price-monitor-app
```

## Krok 3: Konfiguracja

Skopiuj przyk≈Çadowy plik konfiguracyjny:
```bash
cp backend/.env.example backend/.env
```

**Minimalna konfiguracja (dzia≈Ça od razu):**
Plik `backend/.env` jest ju≈º skonfigurowany z domy≈õlnymi warto≈õciami.

**Opcjonalna konfiguracja email** (je≈õli chcesz alerty):
Edytuj `backend/.env`:
```env
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=twoj-email@gmail.com
SMTP_PASSWORD=haslo-aplikacji
SMTP_FROM=twoj-email@gmail.com
```

## Krok 4: Uruchomienie

### Spos√≥b 1: U≈ºyj Makefile (zalecane)

```bash
make install
```

To polecenie:
- Zbuduje wszystkie kontenery
- Uruchomi wszystkie serwisy
- Utworzy u≈ºytkownika admin
- Poka≈ºe dane logowania

### Spos√≥b 2: Manualnie

```bash
# Zbuduj i uruchom
docker-compose up -d

# Poczekaj 30 sekund na uruchomienie bazy danych

# Utw√≥rz u≈ºytkownika admin
docker-compose exec backend python -c "
from app.models.database import SessionLocal
from app.models.models import User
from app.api.auth import get_password_hash

db = SessionLocal()
user = User(
    email='admin@example.com',
    hashed_password=get_password_hash('admin123'),
    full_name='Administrator',
    is_superuser=True
)
db.add(user)
db.commit()
print('‚úÖ U≈ºytkownik utworzony: admin@example.com / admin123')
"
```

## Krok 5: Weryfikacja

Sprawd≈∫ czy wszystko dzia≈Ça:
```bash
docker-compose ps
```

Powiniene≈õ zobaczyƒá 7 kontener√≥w w statusie "running":
- `price_monitor_db` (PostgreSQL)
- `price_monitor_redis` (Redis)
- `price_monitor_backend` (FastAPI)
- `price_monitor_celery_worker` (Celery Worker)
- `price_monitor_celery_beat` (Celery Scheduler)
- `price_monitor_frontend` (React)
- `price_monitor_nginx` (Nginx)

## Krok 6: Pierwsze logowanie

1. Otw√≥rz przeglƒÖdarkƒô: **http://localhost**
2. Zaloguj siƒô:
   - Email: `admin@example.com`
   - Has≈Ço: `admin123`

## Krok 7: Dodaj pierwszy produkt

1. Kliknij **Products** w menu
2. Kliknij **+ Add Product**
3. Wype≈Çnij formularz:
   ```
   Name: iPhone 15 Pro
   SKU: IPHONE-15-PRO-256
   EAN: 0195949038488
   Category: Electronics
   Brand: Apple
   Base Price: 5999
   ```
4. Kliknij **Add Product**

## Krok 8: Dodaj ≈∫r√≥d≈Ço (np. Allegro)

1. Kliknij **Sources** w menu
2. Kliknij **+ Add Source**
3. Wype≈Çnij formularz:
   ```
   Name: Allegro
   Type: marketplace
   Base URL: https://allegro.pl
   Scraper Config:
   {
     "price_selector": "[data-box-name='Price'] span",
     "availability_selector": "button[data-role='buy-button']",
     "use_browser": true
   }
   ```
4. Kliknij **Add Source**

## Krok 9: Po≈ÇƒÖcz produkt ze ≈∫r√≥d≈Çem

U≈ºyj API lub dodaj przez konsole:
```bash
docker-compose exec backend python -c "
from app.models.database import SessionLocal
from app.models.models import ProductSource

db = SessionLocal()
ps = ProductSource(
    product_id=1,
    source_id=1,
    source_url='https://allegro.pl/oferta/iphone-15-pro-256gb-1234567890',
    is_active=True
)
db.add(ps)
db.commit()
print('‚úÖ Produkt po≈ÇƒÖczony ze ≈∫r√≥d≈Çem')
"
```

## Krok 10: Uruchom pierwszy scraping

```bash
# Rƒôcznie uruchom sprawdzanie cen
docker-compose exec celery_worker celery -A app.tasks.celery_app call app.tasks.scraping_tasks.scrape_product --args='[1, 1]'
```

Sprawd≈∫ wyniki w zak≈Çadce **Products** ‚Üí kliknij na produkt ‚Üí zobacz historiƒô cen.

## üéâ Gratulacje!

Twoja aplikacja dzia≈Ça! Teraz mo≈ºesz:

### Dodaƒá wiƒôcej produkt√≥w
U≈ºyj funkcji **Bulk Import** lub API do importu z CSV.

### Skonfigurowaƒá alerty
Id≈∫ do **Alerts** ‚Üí ustaw alerty cenowe.

### Automatyczny scraping
System automatycznie sprawdza ceny raz dziennie o 2:00.
Zmie≈Ñ harmonogram w `backend/app/tasks/celery_app.py`:
```python
celery_app.conf.beat_schedule = {
    'scrape-all-products-daily': {
        'task': 'app.tasks.scraping_tasks.scrape_all_products',
        'schedule': crontab(hour=2, minute=0),  # Zmie≈Ñ tutaj
    },
}
```

### Generowaƒá raporty
Id≈∫ do **Reports** ‚Üí wybierz typ i format ‚Üí pobierz.

## üìä Monitorowanie

### Zobacz logi
```bash
# Wszystkie logi
docker-compose logs -f

# Tylko backend
docker-compose logs -f backend

# Tylko celery worker
docker-compose logs -f celery_worker
```

### Status zada≈Ñ Celery
```bash
docker-compose exec celery_worker celery -A app.tasks.celery_app inspect active
```

## ‚ö†Ô∏è RozwiƒÖzywanie problem√≥w

### Problem: Kontener nie startuje
```bash
docker-compose down
docker-compose up -d
docker-compose logs -f
```

### Problem: Baza danych nie dzia≈Ça
```bash
docker-compose down -v  # UWAGA: usuwa wszystkie dane!
docker-compose up -d
```

### Problem: Playwright nie dzia≈Ça
```bash
docker-compose exec backend playwright install chromium
docker-compose restart celery_worker
```

### Problem: Frontend nie ≈ÇƒÖczy siƒô z backend
Sprawd≈∫ `frontend/package.json`:
```json
{
  "proxy": "http://backend:8000"
}
```

## üîß U≈ºyteczne komendy

```bash
# Status wszystkich kontener√≥w
docker-compose ps

# Restart ca≈Çej aplikacji
make restart
# lub
docker-compose restart

# Zatrzymaj aplikacjƒô
make down
# lub
docker-compose down

# Zobacz logi
make logs
# lub
docker-compose logs -f

# Backup bazy danych
make backup

# Wyczyszczenie wszystkiego
make clean  # UWAGA: usuwa wszystkie dane!
```

## üìö Wiƒôcej informacji

- **README.md** - Pe≈Çna dokumentacja
- **docs/API.md** - Dokumentacja API
- **docs/SCRAPING_GUIDE.md** - Przewodnik po scrapingu
- **http://localhost/docs** - Interaktywna dokumentacja API

## üÜò Pomoc

Je≈õli napotkasz problemy:
1. Sprawd≈∫ logi: `docker-compose logs`
2. Sprawd≈∫ dokumentacjƒô w README.md
3. Upewnij siƒô, ≈ºe wszystkie kontenery dzia≈ÇajƒÖ: `docker-compose ps`

---

**Powodzenia! üöÄ**
